{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exercise #1 - Adding More Tools Exercise [Solution]\n","\n","The research workflow currently performs research with an LLM and writes it to a PDF. To add a little more pizaz to your research paper, you'll use AI to generate an image of the research subject.\n","\n","In this exercise, you'll:\n","  - Call tools with your agent\n","  - Extract structured information from LLM responses to coordinate between different tools.\n","\n"],"metadata":{"id":"ekQPgGVwQb1a"}},{"cell_type":"markdown","source":["## Setup\n","\n","Before doing the exercise, you need to:\n","\n","* Install necessary dependencies\n","* Create your `.env` file and supply your API key\n","* Load the environment variables"],"metadata":{"id":"t_uA13X5SYWe"}},{"cell_type":"code","source":["# We'll first install the necessary packages for this workshop.\n","\n","%pip install --quiet litellm reportlab python-dotenv requests"],"metadata":{"id":"m8UH2Il_Sp50","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757714962404,"user_tz":240,"elapsed":20165,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"1ad95e58-ad27-4390-8379-6c030a65678b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["## Create a `.env` File\n","\n","Next you'll create a `.env` file to store your API keys.\n","In the file browser on the left, create a new file and name it `.env`.\n","\n","**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n","To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n","\n","Then double click on the `.env` file and add the following line with your API key.\n","\n","```\n","LLM_API_KEY = YOUR_API_KEY\n","LLM_MODEL = \"openai/gpt-4o\"\n","```\n","\n","By default this notebook uses OpenAI's GPT-4o.\n","If you want to use a different LLM provider, look up the appropriate model name [in their documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key.\n","\n","**To perform image generation, you will need an OpenAI key**"],"metadata":{"id":"HXp3VIAdZuhO"}},{"cell_type":"code","source":["# Create .env file\n","with open(\".env\", \"w\") as fh:\n","  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n","\n","# Now open the file and replace YOUR_API_KEY with your API key"],"metadata":{"id":"tSl-K8ATXLJ3","executionInfo":{"status":"ok","timestamp":1757714967533,"user_tz":240,"elapsed":8,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load environment variables and configure LLM settings\n","\n","import os\n","from dotenv import load_dotenv\n","\n","load_dotenv(override=True)\n","\n","\n","# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n","LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n","LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n","\n","print(\"API Key: \", LLM_API_KEY)"],"metadata":{"id":"fy4s0KTRdWxL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757714991049,"user_tz":240,"elapsed":42,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"74af71f0-1408-4d41-9ab7-887551a76fb9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["API Key:  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\n"]}]},{"cell_type":"markdown","source":["## Define functions\n","\n","In the content notebook there were two functions defined, `llm_call` and `create_pdf`. Run the code to define them here"],"metadata":{"id":"Iw22wN9wX1Ok"}},{"cell_type":"code","source":["from litellm import completion, ModelResponse\n","\n","# Sends user prompt to an LLM and returns response\n","def llm_call(prompt: str, llm_api_key: str, llm_model: str) -> ModelResponse:\n","    response = completion(\n","      model=llm_model,\n","      api_key=llm_api_key,\n","      messages=[{ \"content\": prompt,\"role\": \"user\"}]\n","    )\n","    return response"],"metadata":{"id":"2FEDm6EiYKB2","executionInfo":{"status":"ok","timestamp":1757714998003,"user_tz":240,"elapsed":4167,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from reportlab.lib.pagesizes import letter\n","from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.units import inch\n","import requests\n","from io import BytesIO\n","\n","# Agent tool: converts text content into a PDF\n","def create_pdf(content: str, filename: str = \"research_report.pdf\", image_url: str = None):\n","    doc = SimpleDocTemplate(filename, pagesize=letter)\n","\n","    styles = getSampleStyleSheet()\n","    title_style = ParagraphStyle(\n","        'CustomTitle',\n","        parent=styles['Heading1'],\n","        fontSize=24,\n","        spaceAfter=30,\n","        alignment=1\n","    )\n","\n","    story = []\n","    title = Paragraph(\"Research Report\", title_style)\n","    story.append(title)\n","    story.append(Spacer(1, 20))\n","\n","    if image_url is not None:\n","      img_response = requests.get(image_url)\n","      img_buffer = BytesIO(img_response.content)\n","      img = RLImage(img_buffer, width=5*inch, height=5*inch)\n","      story.append(img)\n","      story.append(Spacer(1, 20))\n","\n","    paragraphs = content.split('\\n\\n')\n","    for para in paragraphs:\n","        if para.strip():\n","            p = Paragraph(para.strip(), styles['Normal'])\n","            story.append(p)\n","            story.append(Spacer(1, 12))\n","\n","    doc.build(story)\n","    return filename"],"metadata":{"id":"sUuRKXiXYNey","executionInfo":{"status":"ok","timestamp":1757714999115,"user_tz":240,"elapsed":378,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Part 1 - Getting the Subject from Our Past Prompt\n","\n","In the workflow from the presentation, you provided a prompt to the LLM to generate research. We now want to create an image to add some fun to our PDF that illustrates the topic of the prompt. This prompt was likely a complete sentence, with more detail than you will need to create the image. We can use the LLM to get the subject of the original prompt.\n","\n","* Call the `llm_call` function with the prompt `Tell me the subject of this sentence and only the subject. Give the most succinct answer you can. No explanation, just an answer. The sentence is:` and provide the `research_prompt` you provided\n","* Recall that `LiteLLM` returns a `ModelResponse`. To retrieve the answer, you need to use the following keys `[\"choices\"][0][\"message\"][\"content\"]`"],"metadata":{"id":"2BE_tNaFU_dP"}},{"cell_type":"code","source":["research_prompt = input(\"Enter your research topic or question: \")"],"metadata":{"id":"THWJVkMfWzK9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757715022116,"user_tz":240,"elapsed":7635,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"6ee95895-84cd-4ba6-e065-710afa37ca5b"},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your research topic or question: give me 2 facts about elephants\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"LfWPp-pTbP9r"}},{"cell_type":"code","source":["subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {research_prompt}\"\n","research_subject = llm_call(subject_prompt, LLM_API_KEY, LLM_MODEL)[\"choices\"][0][\"message\"][\"content\"]\n","print(research_subject)"],"metadata":{"id":"boGCFsUFZtl0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757715025426,"user_tz":240,"elapsed":1180,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"bda1aa9f-e3da-4d06-b211-45185b6f3444"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Elephants\n"]}]},{"cell_type":"markdown","source":["## Part #2 - Generate an Image of the Subject\n","\n","Now that we have the subect of your prompt, we will generate an image of it by passing it into the `generate_ai_image` as a parameter.\n","\n","* Create a prompt for the image generation that includes the subject of the research report\n","  * Example prompt: f\"A cute, natural image of {subject}.\"\n","* Add the missing key word arguments to the `image_generation` call. The arguments you need to add are:\n","  * `prompt` - The prompt you crafted to generate the image\n","  * `model` - Since we are using OpenAI, let's use `dall-e-3`\n","  * `api_key` - Your API key\n","* In the second code block, call the function and store the result in the variable `research_subject`."],"metadata":{"id":"HNrBOqdISGll"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"nRYQtg_fO-GD","executionInfo":{"status":"ok","timestamp":1757715030944,"user_tz":240,"elapsed":8,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}}},"outputs":[],"source":["from litellm import image_generation\n","\n","def generate_ai_image(subject: str, llm_api_key: str, llm_model: str = \"dall-e-3\") -> str:\n","\n","    image_prompt = f\"A cute, natural image of {subject}.\"\n","\n","    response = image_generation(\n","        prompt=image_prompt,\n","        model=llm_model,\n","        api_key=llm_api_key\n","    )\n","\n","    return response\n"]},{"cell_type":"code","source":["from IPython.display import Image, display\n","\n","\n","research_image = generate_ai_image(research_subject, LLM_API_KEY)\n","research_image_url = research_image[\"data\"][0][\"url\"]\n","\n","display(Image(url=research_image_url))"],"metadata":{"id":"wwHsnzrwRnCb","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1757715051536,"user_tz":240,"elapsed":17193,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"b816a716-dedd-448f-e924-c0cdb2e05e2c"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/html":["<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-dXYXVMc9iVJnKMaoF4Urfmge/user-t88qAIypfPBInUHrsxhFzZ2I/img-DvrCtedgKcV1Z3wZyAJiTRZr.png?st=2025-09-12T21%3A10%3A51Z&se=2025-09-12T23%3A10%3A51Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=c6569cb0-0faa-463d-9694-97df3dc1dfb1&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-09-12T18%3A12%3A05Z&ske=2025-09-13T18%3A12%3A05Z&sks=b&skv=2024-08-04&sig=R1D3MApVehvRMdXHTY/g53i7GJz5LOg1DeHXAJXRctk%3D\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Part 3 - Updating the workflow\n","\n","Now that you have an image, you can update the agent workflow to get the topic, make the LLM call, and generate the report.\n","\n","* Add a call to `llm_call` to get the topic of your prompt.\n","  * The `llm_call` function takes in your `resesearch_prompt`, `LLM_API_KEY`, and `LLM_MODEL`.\n","* Add a call to `generate_ai_image` to get an image for your research pdf.\n","  * The `generate_ai_image` function takes in your `research_topic` and `LLM_API_KEY`.\n","* Be sure to extract the appropriate data from the objects returned when calling `llm_call` and `generate_ai_image`\n","  * For `llm_call` it's `[\"choices\"][0][\"message\"][\"content\"]`\n","  * For `generate_ai_image` it's `[\"data\"][0][\"url\"]`\n"],"metadata":{"id":"yoMApjFcdT9O"}},{"cell_type":"code","source":["try:\n","    # Make the API call\n","    print(\"Welcome to the Research Report Generator!\")\n","    research_prompt = input(\"Enter your research topic or question: \")\n","    result = llm_call(research_prompt, LLM_API_KEY, LLM_MODEL)\n","\n","    # Extract the response content\n","    response_content = result[\"choices\"][0][\"message\"][\"content\"]\n","\n","    subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {research_prompt}\"\n","\n","    research_topic_llm_response = llm_call(subject_prompt, LLM_API_KEY, LLM_MODEL)\n","    research_topic = research_topic_llm_response[\"choices\"][0][\"message\"][\"content\"]\n","\n","    ai_image = generate_ai_image(research_topic, LLM_API_KEY)\n","    ai_image_url = ai_image[\"data\"][0][\"url\"]\n","\n","    pdf_filename = create_pdf(response_content, f\"{research_topic}.pdf\", ai_image_url)\n","    print(f\"SUCCESS! PDF created: {pdf_filename}\")\n","except Exception as e:\n","    print(f\"Error: {e}\")"],"metadata":{"id":"QbxWbgrZdipe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757715100047,"user_tz":240,"elapsed":40516,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"80b11f79-90fd-471a-b20e-52882496a52c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Welcome to the Research Report Generator!\n","Enter your research topic or question: Give me 2 facts about elephants\n","SUCCESS! PDF created: Elephants.pdf\n"]}]},{"cell_type":"markdown","source":["Awesome! But think of the things that could go wrong in this application. What if your image generation API went down? What if the PDF creation fails after you've already paid for the LLM call? How can we make this code more durable? We'll find out in the next notebook."],"metadata":{"id":"m9zU16kf5YzP"}}]}