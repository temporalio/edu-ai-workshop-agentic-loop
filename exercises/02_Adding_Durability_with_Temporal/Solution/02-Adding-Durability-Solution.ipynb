{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"history_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exercise #2 - Adding Durability Exercise [Solution]\n","\n","In the first notebook, you created a research workflow which currently performs research with an LLM and writes it to a PDF. To add a little more pizaz to your research paper, you used AI to generate an image of the research subject.\n","\n","Now, you're going to use Temporal to add durability to this code.\n","\n","In this exercise, you'll:\n","\n","- Transform your LLM calls and your execution of tools to Activities\n","- Use a Temporal Workflow to orchestrate your Activities\n","- Observe how Temporal handles your errors\n","- Debug your error and observe your Workflow Execution successfully complete"],"metadata":{"id":"ekQPgGVwQb1a"}},{"cell_type":"markdown","source":["## Setup\n","\n","Before doing the exercise, you need to:\n","\n","- Install necessary dependencies\n","- Create your `.env` file and supply your API key\n","- Load the environment variables\n","- Download and start a local Temporal Service"],"metadata":{"id":"t_uA13X5SYWe"}},{"cell_type":"code","source":["# We'll first install the necessary packages for this workshop.\n","\n","%pip install --quiet temporalio litellm reportlab python-dotenv requests"],"metadata":{"id":"m8UH2Il_Sp50","executionInfo":{"status":"ok","timestamp":1757727269458,"user_tz":240,"elapsed":21551,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"be1fb713-1562-40fd-e5c8-3274d77f9b67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["### Create a `.env` File\n","\n","Next you'll create a `.env` file to store your API keys.\n","In the file browser on the left, create a new file and name it `.env`.\n","\n","**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n","To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n","\n","Then double click on the `.env` file and add the following line with your API key.\n","\n","```\n","LLM_API_KEY = YOUR_API_KEY\n","LLM_MODEL = \"openai/gpt-4o\"\n","```\n","\n","By default this notebook uses OpenAI's GPT-4o.\n","If you want to use a different LLM provider, look up the appropriate model name [in their documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key.\n","\n","**To perform image generation, you will need an OpenAI key**"],"metadata":{"id":"HXp3VIAdZuhO"}},{"cell_type":"code","source":["# Create .env file\n","with open(\".env\", \"w\") as fh:\n","  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n","\n","# Now open the file and replace YOUR_API_KEY with your API key"],"metadata":{"id":"tSl-K8ATXLJ3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Add Your LLM API Key **Before** Running the Following Code Block"],"metadata":{"id":"4PU75hvN-Qed"}},{"cell_type":"code","source":["# Load environment variables and configure LLM settings\n","import os\n","from dotenv import load_dotenv\n","\n","load_dotenv(override=True)\n","\n","# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n","LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n","LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n","print(\"API Key: \", LLM_API_KEY)"],"metadata":{"id":"fy4s0KTRdWxL","executionInfo":{"status":"ok","timestamp":1757727435260,"user_tz":240,"elapsed":15,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a68d8068-e0ed-4278-8cfd-1a5f05ca9b0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["API Key:  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\n"]}]},{"cell_type":"markdown","source":["### Setting Up the Temporal Service\n","\n","Run the following blocks to setup & enable a local Temporal Service"],"metadata":{"id":"90AW0nTB0P2V"}},{"cell_type":"code","source":["# allows us to run the Temporal Asyncio event loop within the event loop of Jupyter Notebooks\n","import nest_asyncio\n","nest_asyncio.apply()"],"metadata":{"id":"TLHoJlR4R8Au"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download the Temporal CLI.\n","\n","!curl -sSf https://temporal.download/cli.sh | sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scrsqIOy0a_8","executionInfo":{"status":"ok","timestamp":1757727445668,"user_tz":240,"elapsed":2318,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"795ce7c7-8142-47f9-b6b6-5428c83b23e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mtemporal:\u001b[0m Downloading Temporal CLI latest\n","\u001b[1mtemporal:\u001b[0m Temporal CLI installed at /root/.temporalio/bin/temporal\n","\u001b[1mtemporal:\u001b[0m For convenience, we recommend adding it to your PATH\n","\u001b[1mtemporal:\u001b[0m If using bash, run echo export PATH=\"\\$PATH:/root/.temporalio/bin\" >> ~/.bashrc\n"]}]},{"cell_type":"code","source":["# Start the Temporal Dev Server\n","import os\n","import subprocess\n","\n","command = \"/root/.temporalio/bin/temporal server start-dev --ui-port 8000\"\n","temporal_server = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, preexec_fn=os.setsid)"],"metadata":{"id":"Z3oVStbW0kAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Uncomment to kill the dev server\n","# Use this if you need to restart the Temporal Service\n","# Kill the Temporal Dev Server\n","# import signal\n","\n","# os.killpg(os.getpgid(temporal_server.pid), signal.SIGTERM)"],"metadata":{"id":"wK7nqCng1b0a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 1 - Running Your First Workflow\n","\n","In the content notebook, you defined the Models, Activities, and Workflows. Fill in the missing parts, then run the code below again, and to get practice running a Temporal Workflow.\n","\n","**This code should run with 0 modifications.**"],"metadata":{"id":"Iw22wN9wX1Ok"}},{"cell_type":"markdown","source":["### Models\n"],"metadata":{"id":"lSWFzYyb2UBJ"}},{"cell_type":"code","source":["from dataclasses import dataclass\n","\n","@dataclass\n","class LLMCallInput:\n","  prompt: str\n","  llm_api_key: str\n","  llm_model: str\n","\n","@dataclass\n","class PDFGenerationInput:\n","  content: str\n","  image_url: str | None = None\n","  filename: str = \"research_pdf\"\n","\n","@dataclass\n","class GenerateReportInput:\n","    prompt: str\n","\n","@dataclass\n","class GenerateReportOutput:\n","    result: str"],"metadata":{"id":"pMHdjdjL2FlT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Activities:"],"metadata":{"id":"Ys60mB8o2Vib"}},{"cell_type":"code","source":["from io import BytesIO\n","\n","import requests\n","from litellm import completion, ModelResponse\n","from reportlab.lib.pagesizes import letter\n","from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage\n","from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n","from reportlab.lib.units import inch\n","\n","from temporalio import activity\n","\n","@activity.defn\n","def llm_call(input: LLMCallInput) -> ModelResponse:\n","    response = completion(\n","      model=input.llm_model,\n","      api_key=input.llm_api_key,\n","      messages=[{ \"content\": input.prompt,\"role\": \"user\"}]\n","    )\n","    return response\n","\n","@activity.defn\n","def create_pdf_activity(input: PDFGenerationInput) -> str:\n","    doc = SimpleDocTemplate(f\"{input.filename}.pdf\", pagesize=letter)\n","\n","    styles = getSampleStyleSheet()\n","    title_style = ParagraphStyle(\n","        'CustomTitle',\n","        parent=styles['Heading1'],\n","        fontSize=24,\n","        spaceAfter=30,\n","        alignment=1\n","    )\n","\n","    story = []\n","    title = Paragraph(\"Research Report\", title_style)\n","    story.append(title)\n","    story.append(Spacer(1, 20))\n","\n","    if input.image_url is not None:\n","      img_response = requests.get(input.image_url)\n","      img_buffer = BytesIO(img_response.content)\n","      img = RLImage(img_buffer, width=5*inch, height=5*inch)\n","      story.append(img)\n","      story.append(Spacer(1, 20))\n","\n","    paragraphs = input.content.split('\\n\\n')\n","    for para in paragraphs:\n","        if para.strip():\n","            p = Paragraph(para.strip(), styles['Normal'])\n","            story.append(p)\n","            story.append(Spacer(1, 12))\n","\n","    doc.build(story)\n","    return input.filename"],"metadata":{"id":"2FEDm6EiYKB2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Workflow\n","\n","A Workflow coordinates the execution of your Activities.\n","\n","1. In the first `execute_activity` call, call your `llm_call` Activity.\n","2. In the second `execute_activity` call where you call `create_pdf_activity`, set your Start-to-Close Timeout to be 10 seconds. This is the maximum time allowed for a single attempt of an Activity to execute."],"metadata":{"id":"uS8SgW472Xto"}},{"cell_type":"code","source":["import asyncio\n","from datetime import timedelta\n","import logging\n","\n","from temporalio import workflow\n","\n","# sandboxed=False is a Notebook only requirement. You normally don't do this\n","@workflow.defn(sandboxed=False)\n","class GenerateReportWorkflow:\n","\n","    @workflow.run\n","    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n","\n","        llm_call_input = LLMCallInput(prompt=input.prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n","\n","        research_facts = await workflow.execute_activity(\n","            llm_call,\n","            llm_call_input,\n","            start_to_close_timeout=timedelta(seconds=30),\n","        )\n","\n","        workflow.logger.info(\"Research complete!\")\n","\n","        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"])\n","\n","        pdf_filename = await workflow.execute_activity(\n","            create_pdf_activity,\n","            pdf_generation_input,\n","            start_to_close_timeout=timedelta(seconds=10),\n","        )\n","\n","        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"],"metadata":{"id":"sUuRKXiXYNey"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Worker\n","\n","Workers wait for tasks to do, such as an Activity or Workflow Task, and execute them.\n","\n","Workers have Workflows and Activities registered to them so the Worker knows what to execute. Pass in your `llm_call` and `create_pdf_activity` Activities into the list so that they are registered to the Worker."],"metadata":{"id":"qlbhDExL4C1n"}},{"cell_type":"code","source":["from temporalio.client import Client\n","from temporalio.worker import Worker\n","import concurrent.futures\n","\n","async def run_worker() -> None:\n","    logging.basicConfig(level=logging.INFO)\n","    logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n","\n","    # Create client connected to server at the given address\n","    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n","\n","    # Run the Worker\n","    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n","        worker = Worker(\n","            client,\n","            task_queue=\"research\", # the task queue the Worker is polling\n","            workflows=[GenerateReportWorkflow], # register the Workflow\n","            activities=[llm_call, create_pdf_activity], # register the Activities\n","            activity_executor=activity_executor\n","        )\n","\n","        print(f\"Starting the worker....\")\n","        await worker.run()"],"metadata":{"id":"MRaj3kXa4Bpt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start a new worker\n","worker = asyncio.create_task(run_worker())"],"metadata":{"id":"BzJrRRh_IrhO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Client\n","\n","You request execution of your Workflow by using a Temporal Client.\n","\n","In the Client that you specfiy your Workflow to run, the data, you need to specify a Task Queue. This Task Queue must exactly match the Task Queue specified in the Worker.\n"],"metadata":{"id":"MlSHFgmG70f-"}},{"cell_type":"code","source":["import asyncio\n","\n","from temporalio.client import Client\n","\n","# Create client connected to server at the given address\n","client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n","\n","print(\"Welcome to the Research Report Generator!\")\n","prompt = input(\"Enter your research topic or question: \").strip()\n","\n","if not prompt:\n","    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n","    print(f\"No prompt entered. Using default: {prompt}\")\n","\n","# Asynchronous start of a Workflow\n","handle = await client.start_workflow(\n","    GenerateReportWorkflow.run,\n","    GenerateReportInput(prompt=prompt),\n","    id=\"generate-research-report-workflow\", # user-defined Workflow identifier, which typically has some business meaning\n","    task_queue=\"research\",  # the task-queue that your Worker is polling\n",")\n","\n","print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"],"metadata":{"id":"cJMyyRU97oTj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757727517843,"user_tz":240,"elapsed":7586,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"9d21e45f-4ecf-4a42-f27e-2d6cb53bf253"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Welcome to the Research Report Generator!\n","Enter your research topic or question: Give me facts about elephants\n","Started workflow. Workflow ID: generate-research-report-workflow, RunID 019940b9-6c36-758f-98c0-d14f26a0eb35\n"]}]},{"cell_type":"markdown","source":["### Review the Workflow Execution in the Web UI"],"metadata":{"id":"YTY339F9EuhQ"}},{"cell_type":"code","source":["# Get the Temporal Web UI URL\n","from google.colab.output import eval_js\n","print(eval_js(\"google.colab.kernel.proxyPort(8000)\"))"],"metadata":{"id":"Zn1LkXCo7ICC","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1757727521437,"user_tz":240,"elapsed":519,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"b926925d-b7ec-4fd2-a507-f85ef525cb30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://8000-m-s-21v33ux0j5jji-b.us-west1-0.prod.colab.dev\n"]}]},{"cell_type":"markdown","source":["### Kill the Worker to Prepare for the next Exercise\n","\n","x = worker.cancel()"],"metadata":{"id":"nliC3O2aEzdg"}},{"cell_type":"markdown","source":["## Part 2 - Getting the Subject from Our Past Prompt by Calling an Activity\n","\n","In this exercise you'll:\n","\n","- Add a call to the `llm_call` Activity in the Workflow\n","- Modify the subsequent Activity call to pass the topic to the `create_pdf` Activity\n","- Start the Worker\n","- Run the Workflow and see it perform a research task, and create a file where the name of the file is the topic of the research"],"metadata":{"id":"2BE_tNaFU_dP"}},{"cell_type":"code","source":["import asyncio\n","from datetime import timedelta\n","import logging\n","\n","from temporalio import workflow\n","\n","# sandboxed=False is a Notebook only requirement. You normally don't do this\n","@workflow.defn(sandboxed=False)\n","class GenerateReportWorkflow:\n","\n","    @workflow.run\n","    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n","\n","        research_input = LLMCallInput(prompt=input.prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n","\n","        research_facts = await workflow.execute_activity(\n","            llm_call,\n","            research_input,\n","            start_to_close_timeout=timedelta(seconds=30), # maximum duration for the LLM call to complete\n","        )\n","\n","        workflow.logger.info(\"Research complete!\")\n","\n","        # Added the subject prompt\n","        subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {input.prompt}\"\n","\n","        # Created an object to pass to the Activity\n","        subject_input = LLMCallInput(prompt=subject_prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n","\n","        # Called the llm_call Activity again with a new prompt\n","        topic_call = await workflow.execute_activity(\n","            llm_call,\n","            subject_input,\n","            start_to_close_timeout=timedelta(seconds=30),\n","        )\n","\n","        # Extracted the topic from the response\n","        topic = topic_call[\"choices\"][0][\"message\"][\"content\"]\n","\n","        # Passed in the topic as the filename so it can be used to name the file\n","        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"], filename=topic)\n","\n","        pdf_filename = await workflow.execute_activity(\n","            create_pdf_activity,\n","            pdf_generation_input,\n","            start_to_close_timeout=timedelta(seconds=10),\n","        )\n","\n","        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"],"metadata":{"id":"pOlBt5yd5W36"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kill any previous workers that may still be running\n","x = worker.cancel()\n","\n","# Start a new worker\n","worker = asyncio.create_task(run_worker())"],"metadata":{"id":"XRFAWSBa4QZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Execute your Workflow\n","\n","import time\n","\n","client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n","\n","print(\"Welcome to the Research Report Generator!\")\n","prompt = input(\"Enter your research topic or question: \").strip()\n","\n","if not prompt:\n","    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n","    print(f\"No prompt entered. Using default: {prompt}\")\n","\n","# Asynchronous start of a Workflow\n","handle = await client.start_workflow(\n","    GenerateReportWorkflow.run,\n","    GenerateReportInput(prompt=prompt),\n","    id=\"generate-research-report-workflow\",\n","    task_queue=\"research\",\n",")\n","\n","print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"],"metadata":{"id":"kgtTTapM6CNy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757727599919,"user_tz":240,"elapsed":4792,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"86a1a9b5-3269-4f31-a96e-f2367a6f5768"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Welcome to the Research Report Generator!\n","Enter your research topic or question: give me facts about elephants\n","Started workflow. Workflow ID: generate-research-report-workflow, RunID 019940ba-acf2-79f2-95a6-fefe18594bbc\n"]}]},{"cell_type":"markdown","source":["### Watch the Execuction in the Web UI\n","\n","Open the Web UI and watch the execution. Find the following items in the Web UI:\n","\n","- How long did the execution of the first call to  `llm_call` take?\n","- How long did the execution of the second call to  `llm_call` take?\n","- What was the output from the second LLM call?"],"metadata":{"id":"zaIYuART6KKY"}},{"cell_type":"code","source":["# Get the Temporal Web UI URL\n","from google.colab.output import eval_js\n","print(eval_js(\"google.colab.kernel.proxyPort(8000)\"))"],"metadata":{"id":"OLg4s8yX6JPX","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1757727601694,"user_tz":240,"elapsed":130,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"8d68e985-be45-432a-f1b6-707eaa293ca2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://8000-m-s-21v33ux0j5jji-b.us-west1-0.prod.colab.dev\n"]}]},{"cell_type":"markdown","source":["## Part 3 - Convert the Image Creation Function to an Activity and Recover from an Error\n","\n","In the first exercise, you called a function to create an image of the topic of the prompt. In this exercise you'll:\n","\n","- Update this function to be an Activity\n","- Register the Activity with the Worker\n","- Call the Activity from within the Workflow\n","- Test your Workflow\n","- Observe your retry policy in your Activity\n","- Fix your error and watch your Workflow successfully complete.\n","\n"],"metadata":{"id":"HNrBOqdISGll"}},{"cell_type":"code","source":["# Add a new model for Activity input\n","@dataclass\n","class GenerateImageInput:\n","    topic: str\n","    llm_api_key: str\n","    llm_model: str = \"dall-e-3\""],"metadata":{"id":"85kUXKuDGbWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nRYQtg_fO-GD"},"outputs":[],"source":["from litellm import image_generation\n","from temporalio import activity\n","from temporalio.exceptions import ApplicationError\n","\n","@activity.defn\n","def generate_ai_image(input: GenerateImageInput) -> ModelResponse:\n","\n","    image_prompt = f\"A cute, natural image of {input.topic}.\"\n","\n","    response = image_generation(\n","        prompt=image_prompt,\n","        model=input.llm_model,\n","        api_key=input.llm_api_key\n","    )\n","\n","    raise ApplicationError( # We are going to intentionally throw an error in your Activity to observe retries.\n","        error_message=\"intentional error\",\n","    )\n","\n","    return response\n"]},{"cell_type":"code","source":["# Call your `generate_ai_image` from your Workflow.\n","\n","import asyncio\n","from datetime import timedelta\n","import logging\n","\n","from temporalio import workflow\n","\n","# sandboxed=False is a Notebook only requirement. You normally don't do this\n","@workflow.defn(sandboxed=False)\n","class GenerateReportWorkflow:\n","\n","    @workflow.run\n","    async def run(self, input: GenerateReportInput) -> GenerateReportOutput:\n","\n","        research_input = LLMCallInput(prompt=input.prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n","\n","        research_facts = await workflow.execute_activity(\n","            llm_call,\n","            research_input,\n","            start_to_close_timeout=timedelta(seconds=30),\n","        )\n","\n","        workflow.logger.info(\"Research complete!\")\n","\n","        subject_prompt = f\"What is the main topic of this sentence? Respond with only the topic in a single word or short phrase. No explanation. The sentence is: {input.prompt}\"\n","        subject_input = LLMCallInput(prompt=subject_prompt, llm_api_key=LLM_API_KEY, llm_model=LLM_MODEL)\n","\n","        topic_call = await workflow.execute_activity(\n","            llm_call,\n","            subject_input,\n","            start_to_close_timeout=timedelta(seconds=30),\n","        )\n","\n","        topic = topic_call[\"choices\"][0][\"message\"][\"content\"]\n","\n","        # Used the new GenerateImageInput dataclass to create the input object for the Activity\n","        image_input = GenerateImageInput(topic=topic, llm_api_key=LLM_API_KEY)\n","\n","        # Called the new generate_ai_image Activity, passing in the image_input parameter made above\n","        ai_image = await workflow.execute_activity(\n","            generate_ai_image,\n","            image_input,\n","            start_to_close_timeout=timedelta(seconds=30),\n","        )\n","\n","        # Exctract the image_url form the Activity call\n","        image_url = ai_image[\"data\"][0][\"url\"]\n","\n","        # Add the image_url parameter to the PDF Generation so the image is included\n","        pdf_generation_input = PDFGenerationInput(content=research_facts[\"choices\"][0][\"message\"][\"content\"], image_url=image_url, filename=topic)\n","\n","        pdf_filename = await workflow.execute_activity(\n","            create_pdf_activity,\n","            pdf_generation_input,\n","            start_to_close_timeout=timedelta(seconds=10),\n","        )\n","\n","        return GenerateReportOutput(result=f\"Successfully created research report PDF: {pdf_filename}\")"],"metadata":{"id":"CVHUEi9kGuIS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Register the Activity with the Worker\n","\n","Don't forget, you have to register Activities with the Worker for them to be executed!"],"metadata":{"id":"mRD_jfd8HtUS"}},{"cell_type":"code","source":["from temporalio.client import Client\n","from temporalio.worker import Worker\n","import concurrent.futures\n","\n","async def run_worker() -> None:\n","    logging.basicConfig(level=logging.INFO)\n","    logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n","\n","    client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n","\n","    # Run the Worker\n","    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n","        worker = Worker(\n","            client,\n","            task_queue=\"research\",\n","            workflows=[GenerateReportWorkflow],\n","            # Registered the new Activity here\n","            activities=[llm_call, create_pdf_activity, generate_ai_image],\n","            activity_executor=activity_executor\n","        )\n","\n","        print(f\"Starting the worker....\")\n","        await worker.run()"],"metadata":{"id":"Ujj6pAGoHsoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kill any previous workers that may still be running\n","x = worker.cancel()\n","\n","# Start a new worker\n","worker = asyncio.create_task(run_worker())"],"metadata":{"id":"KBAre4bDHVw7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the Workflow\n","client = await Client.connect(\"localhost:7233\", namespace=\"default\")\n","\n","print(\"Welcome to the Research Report Generator!\")\n","prompt = input(\"Enter your research topic or question: \").strip()\n","\n","if not prompt:\n","    prompt = \"Give me 5 fun and fascinating facts about tardigrades. Make them interesting and educational!\"\n","    print(f\"No prompt entered. Using default: {prompt}\")\n","\n","# Asynchronous start of a Workflow\n","handle = await client.start_workflow(\n","    GenerateReportWorkflow.run,\n","    GenerateReportInput(prompt=prompt),\n","    id=\"generate-research-report-workflow\",\n","    task_queue=\"research\",\n",")\n","\n","print(f\"Started workflow. Workflow ID: {handle.id}, RunID {handle.result_run_id}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySug_ag_HR-H","outputId":"251b2695-b300-4a33-815e-d1235457ace3","executionInfo":{"status":"ok","timestamp":1757727773438,"user_tz":240,"elapsed":4811,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Welcome to the Research Report Generator!\n","Enter your research topic or question: give me facts about elephants\n","Started workflow. Workflow ID: generate-research-report-workflow, RunID 019940bd-52bf-7e93-a601-d5b788afa829\n"]}]},{"cell_type":"code","source":["# Get the Temporal Web UI URL\n","from google.colab.output import eval_js\n","print(eval_js(\"google.colab.kernel.proxyPort(8000)\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1757727774900,"user_tz":240,"elapsed":129,"user":{"displayName":"Angela Zhou","userId":"04211316506850475003"}},"outputId":"96123015-3f38-43ad-9fab-213c604c9477","id":"2oWNNIBwHcX9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://8000-m-s-21v33ux0j5jji-b.us-west1-0.prod.colab.dev\n"]}]},{"cell_type":"markdown","source":["## Observing Retries\n","\n","You should see that the `generate_ai_image` Activity is retrying over and over until it succeeds.\n","\n","In our case, this is just an error we are intentionally throwing, but this could just as easily be an internal service that isn't responding, a network outage, an application crashing, or more.\n","\n","Find the answers to these by expanding the `Pending Activity` in your Event History.\n","- What is the message in the Pending Activity?\n","- What retry attempt is it on?\n","- How many seconds until the next retry attempt?\n","\n","Let's fix the error by commenting it out."],"metadata":{"id":"yOtw63BuPpI9"}},{"cell_type":"code","source":["from litellm import image_generation\n","from temporalio import activity\n","from temporalio.exceptions import ApplicationError\n","\n","@activity.defn\n","def generate_ai_image(input: GenerateImageInput) -> ModelResponse:\n","\n","    image_prompt = f\"A cute, natural image of {input.topic}.\"\n","\n","    response = image_generation(\n","        prompt=image_prompt,\n","        model=input.llm_model,\n","        api_key=input.llm_api_key\n","    )\n","\n","    # raise ApplicationError( # We are going to intentionally throw an error in your Activity to observe retries.\n","    #     error_message=\"intentional error\",\n","    # )\n","\n","    return response\n"],"metadata":{"id":"DSFNObu9QCrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Kill any previous workers that may still be running\n","x = worker.cancel()\n","\n","# Start a new worker\n","worker = asyncio.create_task(run_worker())"],"metadata":{"id":"4m5KPfDWQJPo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Observing Workflow Completion\n","\n","Go back to your Web UI, and we’ll now see that the Workflow Execution completes successfully! Temporal preserved its Workflow state through failures and replayed with our updated code, continuing exactly where we left off.\n","\n","This is the power of Temporal - your critical business processes are guaranteed to complete with no manual recovery, no lost data, and no duplicate operations."],"metadata":{"id":"SZDJD8CuQU7w"}}]}