{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mbEBnIn7H1Yg",
        "outputId": "7932f198-5cbd-478a-80a5-641ed5a123a8"
      },
      "outputs": [],
      "source": [
        "%pip install litellm reportlab python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9zkChjcPptZ"
      },
      "source": [
        "# Building an AI Agent\n",
        "\n",
        "In this workshop, we will do the following:\n",
        "- Define Agentic AI\n",
        "- Build an AI agent using tools\n",
        "- Understanding why agents are distributed systems\n",
        "- Identify distributed system challenges for AI agents\n",
        "- Recognize when agents become workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18qFIGPokZO7"
      },
      "source": [
        "## What is an AI Agent?\n",
        "\n",
        "An autonomous system that pursues goals through continuous decision-making and action\n",
        "\n",
        "Think of an AI agent as an autonomous system that doesn't just respond once, but continuously works toward achieving a specific goal. Unlike traditional software that follows predetermined steps, an AI agent makes decisions dynamically based on the current situation and available information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyJ9MCfUkdGm"
      },
      "source": [
        "## Hands-on Moments\n",
        "\n",
        "This is a hands-on workshop!\n",
        "\n",
        "All of the instructors slides and code samples are are executable in the workshop notebooks.\n",
        "We encourage you to follow along and play with the samples!\n",
        "\n",
        "At the end of every chapter (notebook) will be a hands-on lab.\n",
        "This a self-guided experience where the instructor gives a prompt (not an llm haha) with a notebook and some starter code and the attendees solve the puzzle.\n",
        "\n",
        "We are going to create a Research Agent that makes a call to the OpenAI API, conducts research on a topic of your choice, and generates a PDF report from that research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXp3VIAdZuhO"
      },
      "source": [
        "## Create a `.env` File\n",
        "\n",
        "Next you'll create a `.env` file to store your API keys.\n",
        "In the file browser on the left, create a new file and name it `.env`.\n",
        "\n",
        "**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n",
        "To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n",
        "\n",
        "Then double click on the `.env` file and add the following line with your API key.\n",
        "\n",
        "```\n",
        "LLM_API_KEY = YOUR_API_KEY\n",
        "LLM_MODEL = \"openai/gpt-4o\"\n",
        "```\n",
        "\n",
        "By default this notebook uses OpenAI's GPT-4o.\n",
        "If you want to use a different LLM provider, look up the appropriate model name [in their documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSl-K8ATXLJ3"
      },
      "outputs": [],
      "source": [
        "# Create .env file\n",
        "with open(\".env\", \"w\") as fh:\n",
        "  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
        "\n",
        "# Now open the file and replace YOUR_API_KEY with your API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy4s0KTRdWxL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "\n",
        "# Get LLM_API_KEY environment variable\n",
        "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
        "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKQTomi_ODQl"
      },
      "source": [
        "## Prompting the LLM\n",
        "\n",
        "For it to be classified as an agent, it must prompt an LLM.\n",
        "\n",
        "We use `litellm` here so you can use any LLM you please. All you need to do is provide an API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3yhd-464Imwb",
        "outputId": "e55472cf-6dd6-4166-e8be-232dd1c6d612"
      },
      "outputs": [],
      "source": [
        "from litellm import completion, ModelResponse\n",
        "\n",
        "\n",
        "def llm_call(prompt: str, llm_api_key: str, llm_model: str) -> ModelResponse:\n",
        "    response = completion(\n",
        "      model=llm_model,\n",
        "      api_key=llm_api_key,\n",
        "      messages=[{ \"content\": prompt,\"role\": \"user\"}]\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# Change this to a fun prompt of your choice!\n",
        "prompt = \"Give me 5 fun Tardigrade facts in the form of a sea shanty.\"\n",
        "\n",
        "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQhhd2TcPbyw"
      },
      "source": [
        "## Prompting the User\n",
        "\n",
        "Now that we have our LLM call, we can write the code to prompt the user for their research topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO4qfPdSOCyI"
      },
      "outputs": [],
      "source": [
        "# Make the API call\n",
        "print(\"Welcome to the Research Report Generator!\")\n",
        "prompt = input(\"Enter your research topic or question: \")\n",
        "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)\n",
        "\n",
        "# Extract the response content\n",
        "response_content = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(\"Research complete!\")\n",
        "print(\"-\"*80)\n",
        "print(response_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7pd_Qnwa4BF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSZSA31HY2-p"
      },
      "source": [
        "## Generating a PDF\n",
        "\n",
        "Once you have your research data, you'll write it out to a PDF.\n",
        "We'll use this later as a tool for our Agent to call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcZJej_5Y8Nm"
      },
      "outputs": [],
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib.units import inch\n",
        "\n",
        "def create_pdf(content: str, filename: str = \"research_report.pdf\") -> str:\n",
        "    doc = SimpleDocTemplate(filename, pagesize=letter)\n",
        "\n",
        "    styles = getSampleStyleSheet()\n",
        "    title_style = ParagraphStyle(\n",
        "        'CustomTitle',\n",
        "        parent=styles['Heading1'],\n",
        "        fontSize=24,\n",
        "        spaceAfter=30,\n",
        "        alignment=1\n",
        "    )\n",
        "\n",
        "    story = []\n",
        "    title = Paragraph(\"Research Report\", title_style)\n",
        "    story.append(title)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    paragraphs = content.split('\\n\\n')\n",
        "    for para in paragraphs:\n",
        "        if para.strip():\n",
        "            p = Paragraph(para.strip(), styles['Normal'])\n",
        "            story.append(p)\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "    doc.build(story)\n",
        "    return filename\n",
        "\n",
        "create_pdf(\"Hello PDF!\", filename=\"test.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf1eZE8LeRB5"
      },
      "source": [
        "## Open the PDF\n",
        "\n",
        "Download the `test.pdf` PDF and open it. You should see a title **Research Report** and the words **Hello PDF!** in the document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alyrd1xbiC4N"
      },
      "source": [
        "## Bringing it all together\n",
        "\n",
        "You now have multiple functions that you can execute to achieve a task.\n",
        "Next, write the code to bring this all together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9dmy84DiQOD"
      },
      "outputs": [],
      "source": [
        "# Make the API call\n",
        "print(\"Welcome to the Research Report Generator!\")\n",
        "prompt = input(\"Enter your research topic or question: \")\n",
        "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)\n",
        "\n",
        "# Extract the response content\n",
        "response_content: str = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "pdf_filename = create_pdf(response_content, \"research_report.pdf\")\n",
        "print(f\"SUCCESS! PDF created: {pdf_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3GhdUXmiycf"
      },
      "source": [
        "## The Foundations of an Agentic Application\n",
        "\n",
        "You now have the foundations of an Agentic AI application.\n",
        "\n",
        "What makes this agentic?\n",
        "1. It's goal-oriented: it has a clear objective (generate a research report)\n",
        "2. Tool usage: it combines multiple capabilities (LLM reasoning + PDF generation)\n",
        "3. Autonomous decision making: the LLM decides how to structure and present the research\n",
        "\n",
        "The functions you created are your \"tools\": `llm_call` and `create_pdf`. Some may think that an Agentic AI must have a loop, but that's not the case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gnTPrw3yNcD"
      },
      "source": [
        "## Agentic Challenges\n",
        "\n",
        "However, there are a few significant challenges to getting production AI at scale.\n",
        "\n",
        "- Network resources (APIs and databases) go down\n",
        "- Rate limitting\n",
        "- LLMs are inherently non-deterministic\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_26Y2tjERPHq"
      },
      "source": [
        "## Agents Don't Work in Isolation\n",
        "\n",
        "* They calling other agents which call other agents, creating complex networks. Each agent has its own logic and potential failure points.\n",
        "* Each of these nodes has its own\n",
        "  * Event loop\n",
        "  * Decision-making process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-cD7kk0rTqL"
      },
      "source": [
        "## Agents Call Other Agents\n",
        "\n",
        " Your research agent might:\n",
        "  * Call a \"Web Scraper\" agent to gather sources\n",
        "  * Call a \"Fact Checker\" agent to verify claims\n",
        "  * Call a \"Citation\" agent to format references\n",
        "  * Call a \"PDF Generator\" agent (what you built!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIkENgxorl8I"
      },
      "source": [
        "## Your Simple Agent in Production\n",
        "\n",
        "  What you built:\n",
        "  - 1 LLM call\n",
        "  - 1 PDF generation\n",
        "\n",
        "  In production, this becomes:\n",
        "  - Multiple LLM calls across different agents\n",
        "  - External API calls (web scraping, databases)\n",
        "  - File system operations\n",
        "  - Network failures at any step\n",
        "  - Need to coordinate responses from multiple agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hcPLb8GWhpc"
      },
      "source": [
        "## Agents are Distributed Systems\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1yynE1_HDDVuFQjaesFcxyds045MzTkfo' />\n",
        "<figcaption>The Truth About AI Agents</figcaption></center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl6jmr_tvG86"
      },
      "source": [
        "## This is Why Agents == Workflows\n",
        "\n",
        "  Your research agent is actually:\n",
        "  1. Accept user input\n",
        "    - Possible problems: input validation service, rate limitting\n",
        "  2. Call the LLM for research\n",
        "    - Possible problems: Internet connection, API down, rate limitting, timeout\n",
        "  3. Generate PDF\n",
        "    - Possible problems: Memory limits\n",
        "  4. Return success/failure\n",
        "    - Possible problem: Connection dropped\n",
        "\n",
        "  Each step can fail.\n",
        "  Each step might need different agents.\n",
        "  This is a **workflow** - and workflows need orchestration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbw85OliybvN"
      },
      "source": [
        "---\n",
        "# Exercise 1 - Adding More Tools\n",
        "\n",
        "* In these exercises you will:\n",
        "  * **FILL IN**\n",
        "* Go to the **Exercise** Directory in the Google Drive and open the **Practice** Directory\n",
        "* Open _01-An-AI-Agent-Practice.ipynb_ and follow the instructions\n",
        "* If you get stuck, raise your hand and someone will come by and help. You can also check the `Solution` directory for the answers\n",
        "* **You have 5 mins**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
