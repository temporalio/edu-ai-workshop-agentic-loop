{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agents\n",
    "\n",
    "In this section, we'll explore what makes an AI system \"agentic\" and why building these systems reliably is more challenging than simple chains. You'll:\n",
    "\n",
    "- Understand LLM agency\n",
    "- Cover a bit of context engineering\n",
    "- Create some tools\n",
    "- Build a couple of durable AI agents (non-looping, and looping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo (Expand for instructor notes or to run on your own)\n",
    "<!--\n",
    "1. Clone this repository: `https://github.com/cdavisafc/non-deterministic-ai-agents`. The instructions will also be in the README.\n",
    "2. Run the Worker: `uv run python -m worker`\n",
    "3. Start the agent: `uv run python -m start_workflow`\n",
    "4. Emphasize that this demo showcases the core principle of agentic applications: we give **agency** to the **LLM** to drive the flow of the application. Unlike traditional applications where developers hardcode every decision and branching path, this agent makes its own choices at runtime. The LLM decides which actions to take, when to gather more information, and when the goal has been achievedâ€”all autonomously.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Build Another Agent!\n",
    "\n",
    "First, let's set up your notebook. Run the following code blocks to install various packages and tools necessary to run this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Setup\n",
    "\n",
    "Run the following code blocks to install various packages and tools necessary to run this notebook\n",
    "\n",
    "**Be sure to add your .env file again. It doesn't persist across notebooks or sesions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll first install the necessary packages for this workshop.\n",
    "\n",
    "%pip install --quiet temporalio python-dotenv openai httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file\n",
    "with open(\".env\", \"w\") as fh:\n",
    "  fh.write(\"OPENAI_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
    "\n",
    "  # Now open the file and replace YOUR_API_KEY with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and configure LLM settings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Get OPENAI_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", None)\n",
    "print(\"OPENAI_API_KEY\", OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows us to run the Temporal Asyncio event loop within the event loop of Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Running this will download the Temporal CLI\n",
    "\n",
    "!curl -sSf https://temporal.download/cli.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Sure Your Temporal Web UI is Running\n",
    "\n",
    "1. You should have the Temporal Server running in your terminal (run `temporal server start-dev` if not).\n",
    "2. Then in your `Ports` tab on the bottom of this screen, find `8233` and click on the Globe icon to open the Temporal Web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Our Agent: Step by Step\n",
    "\n",
    "#### Step 1 - Create the Request Dataclass\n",
    "\n",
    "First, we'll create a dataclass that packages all the parameters needed for our LLM calls. This groups together the model name, agent instructions, conversation input, and available tools in one structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this code block to load it into the program\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@dataclass\n",
    "class OpenAIResponsesRequest:\n",
    "    model: str\n",
    "    instructions: str\n",
    "    input: object\n",
    "    tools: list[dict[str, Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create the Activity for LLM Invocations\n",
    "\n",
    "We will create an Activity which invokes the OpenAI LLM, taking in our `OpenAIResponsesRequest` dataclass.\n",
    "\n",
    "It's a reusable function that handles all communication with OpenAI's LLM throughout our agent's execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Supply the `OpenAIResponsesRequest` we just loaded in as the `request` for the parameter\n",
    "# Step 2: Run this code block to load it into the program\n",
    "from temporalio import activity\n",
    "from openai import AsyncOpenAI\n",
    "from openai.types.responses import Response\n",
    "\n",
    "@activity.defn\n",
    "async def create(request: ) -> Response: # TODO: Supply the `OpenAIResponsesRequest` as the `request` for the parameter\n",
    "    # Temporal best practice: Disable retry logic in OpenAI API client library.\n",
    "    client = AsyncOpenAI(max_retries=0)\n",
    "\n",
    "    resp = await client.responses.create(\n",
    "        model=request.model,\n",
    "        instructions=request.instructions,\n",
    "        input=request.input,\n",
    "        tools=request.tools,\n",
    "        timeout=30,\n",
    "    )\n",
    "\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"create_activity_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create the Helper Function\n",
    "\n",
    "Before we build our tool that fetches weather alerts, we need a helper function that converts Pydantic models into OpenAI's tool definition format.\n",
    "\n",
    "The `oai_responses_tool_from_model` function accepts a tool name, description, and a Pydantic model, then returns JSON in the format expected by OpenAI's Responses API tool definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this code block\n",
    "from openai.lib._pydantic import to_strict_json_schema\n",
    "from pydantic import BaseModel\n",
    "\n",
    "def oai_responses_tool_from_model(name: str, description: str, model: type[BaseModel]):\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"parameters\": to_strict_json_schema(model),\n",
    "        \"strict\": True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Set Up the National Weather Service API Wrapper\n",
    "\n",
    "Before our agent can fetch weather alerts, we need to create helper functions that know how to communicate with the [National Weather Service API](https://www.weather.gov/documentation/services-web-api), specifically for the weather alerts endpoint for a certain state.\n",
    "\n",
    "These helper functions will be used by our Activity in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this code block\n",
    "from typing import Any\n",
    "import httpx\n",
    "import json\n",
    "\n",
    "# Constants for the National Weather Service API\n",
    "NWS_API_BASE = \"https://api.weather.gov\"\n",
    "USER_AGENT = \"weather-app/1.0\"\n",
    "\n",
    "def _alerts_url(state: str) -> str:\n",
    "    \"\"\"Build the NWS API URL for a given state.\"\"\"\n",
    "    return f\"{NWS_API_BASE}/alerts/active/area/{state}\"\n",
    "\n",
    "# External calls will happen via activities\n",
    "async def _make_nws_request(url: str) -> dict[str, Any] | None:\n",
    "    \"\"\"Make a request to the NWS API with proper error handling.\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": USER_AGENT,\n",
    "        \"Accept\": \"application/geo+json\"\n",
    "    }\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(url, headers=headers, timeout=5.0)\n",
    "        response.raise_for_status()\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Build the Tool for the OpenAI Responses API\n",
    "\n",
    "Now we'll create the Pydantic model that defines what parameters the tool accepts, then use our helper function to convert it into OpenAI's tool definition format. \n",
    "\n",
    "We will assign this to our tool registry, `WEATHER_ALERTS_TOOL_OAI`, for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: In the `description` for state, set it to \"Two-letter US state code (e.g. CA, NY)\"\n",
    "# Step 2: Run this code block\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GetWeatherAlertsRequest(BaseModel):\n",
    "    state: str = Field(description=\"\")  # TODO: Set the description to be \"Two-letter US state code (e.g. CA, NY)\"\n",
    "\n",
    "WEATHER_ALERTS_TOOL_OAI: dict[str, Any] = oai_responses_tool_from_model(\n",
    "    \"get_weather_alerts\", # name \n",
    "    \"Get weather alerts for a US state.\", # description\n",
    "    GetWeatherAlertsRequest) # model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"GetWeatherAlertsRequest_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Implement the Activity\n",
    "\n",
    "We'll create the Activity function that executes when the LLM decides to use this tool. This function calls the NWS API and returns the weather alert data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: After the `await`, call the `_make_nws_request` Activity you ran earlier.\n",
    "# Remember: External calls will happen via Activities.\n",
    "# Step 2: Run this code block\n",
    "from temporalio import activity\n",
    "\n",
    "@activity.defn\n",
    "async def get_weather_alerts(weather_alerts_request: GetWeatherAlertsRequest) -> str:\n",
    "    \"\"\"Get weather alerts for a US state.\n",
    "\n",
    "    Args:\n",
    "        state: Two-letter US state code (e.g. CA, NY)\n",
    "    \"\"\"\n",
    "    data = await \"\"(_alerts_url(weather_alerts_request.state)) # TODO: Call the `_make_nws_request` Activity you ran earlier\n",
    "    return json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"get_weather_alerts_activity_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Create the Agent\n",
    "\n",
    "Now we'll create the agent, which is implemented as the **ToolCallingWorkflow**. This Workflow ties everything together:\n",
    "\n",
    "1. **Makes an initial LLM call** with the user's input and available tools\n",
    "2. **Checks if the LLM wants to call a tool** by examining the response type\n",
    "3. **Executes the tool** if requested\n",
    "4. **Makes a second LLM call** with the tool results to get a final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Call the `create` Activity for the initial LLM call\n",
    "# Step 2: Fill in the `OpenAIResponsesRequest` with `system_instructions`, `input_list`, and `WEATHER_ALERTS_TOOL_OAI`.\n",
    "# Step 3: Execute the get_weather_alerts activity when a tool is called\n",
    "# Step 4: Run this code block to load it into the program\n",
    "\n",
    "from temporalio import workflow\n",
    "from datetime import timedelta\n",
    "import json\n",
    "\n",
    "# sandboxed=False is a Notebook only requirement. You normally don't do this\n",
    "@workflow.defn(sandboxed=False)\n",
    "class ToolCallingWorkflow:\n",
    "    @workflow.run\n",
    "    async def run(self, input: str) -> str:\n",
    "        input_list = [{\"role\": \"user\", \"content\": input}]\n",
    "        \n",
    "        # Initial LLM call with system instructions and tools\n",
    "        system_instructions = \"if no tools seem to be needed, respond in haikus.\"\n",
    "        result = await workflow.execute_activity(\n",
    "            # TODO: Call the `create` Activity here\n",
    "            OpenAIResponsesRequest(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                instructions=\"\",  # TODO: Fill in with system_instructions\n",
    "                input=\"\",  # TODO: Fill in with input_list\n",
    "                tools=[]  # TODO: Fill in tools list with WEATHER_ALERTS_TOOL_OAI\n",
    "            ),\n",
    "            start_to_close_timeout=timedelta(seconds=30),\n",
    "        )\n",
    "        \n",
    "        # Process the LLM response\n",
    "        item = result.output[0]\n",
    "        \n",
    "        # if the result is a tool call, call the tool\n",
    "        if item.type == \"function_call\":\n",
    "            if item.name == \"get_weather_alerts\":\n",
    "\n",
    "                # serialize the output, which is an OpenAI object\n",
    "                input_list += [\n",
    "                    i.model_dump() if hasattr(i, \"model_dump\") else i\n",
    "                    for i in result.output\n",
    "                ]\n",
    "                \n",
    "                result = await workflow.execute_activity(\n",
    "                    \"\", # TODO: Execute the get_weather_alerts activity\n",
    "                    GetWeatherAlertsRequest(state=json.loads(item.arguments)[\"state\"]),\n",
    "                    start_to_close_timeout=timedelta(seconds=30),\n",
    "                )\n",
    "                \n",
    "                # Add tool call result to input list\n",
    "                input_list.append({\n",
    "                    \"type\": \"function_call_output\",\n",
    "                    \"call_id\": item.call_id,\n",
    "                    \"output\": result\n",
    "                })\n",
    "                \n",
    "                result = await workflow.execute_activity(\n",
    "                    create,\n",
    "                    OpenAIResponsesRequest(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        instructions=\"return the tool call result in a readable format\",\n",
    "                        input=input_list,\n",
    "                        tools=[]\n",
    "                    ),\n",
    "                    start_to_close_timeout=timedelta(seconds=30),\n",
    "                )\n",
    "        \n",
    "        result = result.output_text\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"tool_calling_workflow_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Tool-Calling Agent\n",
    "\n",
    "Now let's run our agent by running our Worker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set the Task Queue to be \"tool-calling-python-task-queue\"\n",
    "# Step 2: Register `ToolCallingWorkflow` on this Worker\n",
    "# Step 3: Run this code\n",
    "import concurrent.futures\n",
    "from temporalio.client import Client\n",
    "from temporalio.worker import Worker\n",
    "from temporalio.contrib.pydantic import pydantic_data_converter\n",
    "\n",
    "async def run_worker() -> None:\n",
    "    # Create client connected to server at the given address\n",
    "    client = await Client.connect(\"localhost:7233\", data_converter=pydantic_data_converter)\n",
    "\n",
    "    # Run the Worker\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as activity_executor:\n",
    "        worker = Worker(\n",
    "            client,\n",
    "            task_queue=\"\", # TODO Set the Task Queue to be \"tool-calling-python-task-queue\"\n",
    "            workflows=[], # TODO Register `ToolCallingWorkflow` on this Worker\n",
    "            activities=[create, get_weather_alerts],\n",
    "            activity_executor=activity_executor\n",
    "        )\n",
    "\n",
    "        print(f\"Starting the worker....\")\n",
    "        await worker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"worker_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Worker\n",
    "import asyncio\n",
    "\n",
    "worker = asyncio.create_task(run_worker())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate an Interaction with the Agent\n",
    "\n",
    "In order to interact with this simple AI agent, we create a Temporal client and execute a workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set the task queue of the client to match the task queue the worker is polling\n",
    "# Step 2: Run this code block\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "from temporalio.client import Client\n",
    "from temporalio.contrib.pydantic import pydantic_data_converter\n",
    "\n",
    "async def main():\n",
    "    client = await Client.connect(\n",
    "        \"localhost:7233\",\n",
    "        data_converter=pydantic_data_converter,\n",
    "    )\n",
    "\n",
    "    query = sys.argv[1] if len(sys.argv) > 1 else \"Hello, how are you?\"\n",
    "\n",
    "    # Submit the Tool Calling workflow for execution\n",
    "    result = await client.execute_workflow(\n",
    "        ToolCallingWorkflow,\n",
    "        query,\n",
    "        id=f\"weather-alert-agent-{uuid.uuid4()}\",\n",
    "        task_queue=\"\", # TODO: Set the task queue of the client to match the task queue the worker is polling\n",
    "    )\n",
    "    print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run this cell to load and display the solution\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "solution_file = notebook_dir / \"Solutions_04_AI_Agents\" / \"client_solution.py\"\n",
    "\n",
    "code = solution_file.read_text()\n",
    "\n",
    "print(\"Solution loaded:\")\n",
    "display(Markdown(f\"```python\\n{code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Agent\n",
    "\n",
    "Now let's test the agent with different queries. Run the cells below to see how the agent responds to different types of requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with California weather\n",
    "import sys\n",
    "sys.argv = [\"\", \"Are there any weather alerts in CA?\"]\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with New York weather\n",
    "import sys\n",
    "sys.argv = [\"\", \"Are there any weather alerts in NY?\"]\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test without tools (should get haiku)\n",
    "import sys\n",
    "sys.argv = [\"\", \"Tell me a joke\"]\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe Your Web UI\n",
    "\n",
    "Refresh your Web UI. \n",
    "\n",
    "- What Activities are called for a weather alert Workflow Execution vs. the joke Workflow Execution?\n",
    "- Click on the first create Activity in the weather alert Workflow. What was passed in the input field?\n",
    "- Click on the second create Activity in the weather alert Workflow.  How has the input field changed?\n",
    "\n",
    "A point to make is that the **LLM decides autonomously** whether to use the weather\n",
    "alerts tool or not. You don't hardcode \"if user mentions a state, call the API\" -\n",
    "instead, the LLM evaluates the input and decides if calling `get_weather_alerts`\n",
    "will help achieve the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for attending this workshop. Feedback?\n",
    "\n",
    "Please leave your feedback for this workshop [here](https://docs.google.com/forms/d/e/1FAIpQLSfkHMev6KCNGFHpVNydyjgAh2ALeHNVYv9TaSrAoBsT0KmNHQ/viewform?usp=header)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next? \n",
    "\n",
    "Continue your learning and check out these resources!\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Temporal Docs](https://docs.temporal.io/)\n",
    "- [Free Temporal Courses](https://learn.temporal.io/courses/)\n",
    "- Learn more about [AI Agents with Temporal](https://temporal.io/code-exchange/ai-agent-execution-using-temporal)\n",
    "- Join our [Community Slack](https://t.mp/slack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (edu-ai-workshop-mcp)",
   "language": "python",
   "name": "edu-ai-workshop-mcp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
